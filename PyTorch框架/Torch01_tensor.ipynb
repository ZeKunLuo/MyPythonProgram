{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设置tensor和tensor元素类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "#查看tensor默认数据类型\n",
    "print(torch.tensor([1,1]).dtype)\n",
    "print(torch.tensor([1.1,2]).dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 设置指定类型\n",
    "torch.set_default_dtype(torch.float64)\n",
    "torch.tensor([1.1,2]).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#还可以通过下面形式设置\n",
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "torch.get_default_dtype()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.numel计算张量元素总数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(1,2,3,4,5)\n",
    "torch.numel(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation tensor ops\n",
    "> 随机样本创建操作是一个表,随机样本的创建有下面几种操作\n",
    "torch.rand() \n",
    "torch.rand_like() \n",
    "torch.randn()\n",
    "torch.randn_like() torch.randint() torch.randint_like() torch.randperm()\n",
    "也可以使用torch.empty()使得样本值服从一个更广范围的分布"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.tensor(data, dtype=None, device=None, requires_grad=False, pin_memory=False) → Tensor`\n",
    "```python\n",
    "|-参数解释:\n",
    "    data:数据可以是列表元组或者是Numpy数组,标量或者是其他类型\n",
    "    dtype:数据类型如果None则数据类型来自于data\n",
    "    device:设备设置CPU FOR CPU,CUDA FOR CUDA\n",
    "    requires_grad:自动梯度计算设置返回一个梯度张量,默认为False\n",
    "    pin_memory:锁业内存设置默认False具体理解看下面链接：\n",
    "        http://www.voidcn.com/article/p-fsdktdik-bry.html\n",
    "Warning:torch.tensor()总是在拷贝数据,如果想避免拷贝可以使用torch.Tensor.requires_grad_() or torch.Tensor.detach(),if 有一个Numpy数组需要避免拷贝可以使用torch.as_tensor()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1000, 1.2000],\n",
      "        [1.0000, 2.0000],\n",
      "        [3.0000, 4.0000]])\n",
      "[[6 3 3 5]\n",
      " [9 8 9 5]\n",
      " [5 4 1 8]]\n",
      "tensor([[6, 3, 3, 5],\n",
      "        [9, 8, 9, 5],\n",
      "        [5, 4, 1, 8]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = torch.tensor([[0.1,1.2],[1,2],[3,4]])\n",
    "print(a)\n",
    "c = np.random.randint(10,size=(3,4)) # Numpy随机数组\n",
    "print(c)\n",
    "#将Numpy随机数组转化成tensor\n",
    "print(torch.tensor(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.eye(n,m=None,out=None)`\n",
    "返回一个对角线元素为一的2维张量\n",
    "* n:行数\n",
    "* m:列数\n",
    "* out:输出张量类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.eye(3))\n",
    "print(torch.eye(3,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.from_numpy(ndarray)->tensor`\n",
    "将Numpy数组装换成张量形式且返回的张量tensor和numpy共享同一\n",
    "内存空间修改一个会改变另一个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n",
      "tensor([1, 2, 3, 4], dtype=torch.int32)\n",
      "tensor([0, 2, 3, 4], dtype=torch.int32)\n",
      "[0 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2,3,4])\n",
    "t = torch.from_numpy(a)\n",
    "print(a)\n",
    "print(t)\n",
    "t[0] = 0\n",
    "print(t)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.linspace(start,end,steps=100,out=None)->tensor`\n",
    "返回star和end间元素以等差数列排列个数为steps的一维张量其实就是均匀采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000,  3.2500,  5.5000,  7.7500, 10.0000])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linspace(1,10,steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-10.,  -5.,   0.,   5.,  10.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linspace(-10,10,steps=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.logspace(start,end,steps=100,out=None)->tensor`\n",
    "和上面的线性采样类似,这个是在以10为底的对数函数上的均匀采样范围为$10^{star}到10^{end}$,采样个数为steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e-10, 1.0000e-05, 1.0000e+00, 1.0000e+05, 1.0000e+10])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.logspace(start=-10,end=10,steps=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.ones(*sizes,out=None)->Tensor`\n",
    "返回一个全为1的张量,shape由可变参数sizes定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "#下面三式等价sizes可以为序列\n",
    "print(torch.ones(3,3))\n",
    "print(torch.ones([3,3]))\n",
    "print(torch.ones((3,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.rand(*size,out=None)->tensor`\n",
    "返回一个在[0,1]范围均匀分布的随机数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0261, 0.3571, 0.6326],\n",
      "        [0.1159, 0.8533, 0.4729],\n",
      "        [0.6475, 0.8471, 0.5449]])\n",
      "tensor([0.3332, 0.1701, 0.9111])\n"
     ]
    }
   ],
   "source": [
    "print(torch.rand((3,3)))\n",
    "print(torch.rand(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.randn(*sizes,out=None)->Tensor`\n",
    "\n",
    "返回一个从标准正态分布中抽取出的随机张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4944,  0.2861, -1.0668],\n",
       "        [ 0.8469, -0.8389,  0.0439],\n",
       "        [-0.4375, -1.0182, -0.3186]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn([3,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.randperm(n,out=None)->LongTensor`\n",
    "\n",
    "输入参数`n`返回一个从`0`至`n-1`的一个随机整数排列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 3, 4, 2, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randperm(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.arange(start,end,step=1,out=None)->tensor`\n",
    "\n",
    "返回一个1维张量，长度为floor((end−start)/step),floor代表向下取整。包含从start到end，以step为步长的一组序列值(默认步长为1)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5, 6, 7, 8])\n",
      "tensor([1, 3, 5, 7])\n"
     ]
    }
   ],
   "source": [
    "print(torch.arange(*[1,9]))\n",
    "print(torch.arange(*[1,9],step=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.range(start,end,step=1,out=None)->Tensor`\n",
    "\n",
    "返回一个1维张量，长度为floor((end−start)/step)+1，其中floor代表向下取整数。从start开始，end为结尾，以step为步长的一组值。 step 是两个值之间的间隔，即 Xi+1=Xi+step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.5. Note that arange generates values in [start; end), not [start; end].\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.5. Note that arange generates values in [start; end), not [start; end].\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 3., 5., 7., 9.])\n"
     ]
    }
   ],
   "source": [
    "print(torch.range(1.0,9))\n",
    "print(torch.range(1.0,9,step=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.zeros(*sizes,out=None)->Tensor`\n",
    "\n",
    "返回一个全零张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(*[3,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.cat(tensor,dim=0,out=None)->Tensor`\n",
    "* tensor:张量\n",
    "* dim:连接维度\n",
    "* out:输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch._C' has no attribute '_cuda_setDevice'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-78e63646bec8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36mset_device\u001b[1;34m(device)\u001b[0m\n\u001b[0;32m    298\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_device_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cuda_setDevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch._C' has no attribute '_cuda_setDevice'"
     ]
    }
   ],
   "source": [
    "torch.cuda.set_device(0)\n",
    "a = torch. rand( 1000, 1000) \n",
    "b = torch. rand( 1000, 1000)\n",
    "print(a. matmul( b))\n",
    "print(torch.cuda.is_available())\n",
    "#将 张量 转移 到 GPU\n",
    "a = a.cuda() \n",
    "b = b.cuda()\n",
    "print(a.matmul(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
