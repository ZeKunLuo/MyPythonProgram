{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from  torchvision  import datasets,transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "batch_size = 100\n",
    "cifar_train = datasets.CIFAR10(root = 'CIFAR_10',train = True,transform = transforms.Compose([\n",
    "      transforms.Resize((32,32)),\n",
    "      transforms.ToTensor()]),download = True)\n",
    "train_loader = torch.utils.data.DataLoader(cifar_train,train = True,batch_size=batch_size,shuffle=True)\n",
    "\n",
    "cifar_test = datasets.CIFAR10(root = 'CIFAR_10',train = False,transform = transforms.Compose([\n",
    "         transforms.Resize((32,32)),\n",
    "         transforms.Totensor()]),download = True)\n",
    "test_loader = torch.utils.data.DataLoader(cifar_test,train = False,batch_size = batch_size,shuffle = True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3072)\n",
      "dict_keys(['batch_label', 'labels', 'data', 'filenames'])\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as plt\n",
    "def load(filename):\n",
    "\n",
    "    with open(filename, 'rb') as fo:\n",
    "\n",
    "        data = pickle.load(fo, encoding='latin1')\n",
    "\n",
    "    return data\n",
    "fil = 'E:\\Download\\DigitalImage\\cifar-10-batches-py\\data_batch_1'\n",
    "batch_1 = load(fil)\n",
    "print(batch_1['data'].shape)\n",
    "print(batch_1.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[159 150 153 ...  91  74  76]\n",
      "  [142 146 155 ... 127 122  86]\n",
      "  [109  99 105 ... 137 163  93]\n",
      "  ...\n",
      "  [244 240 241 ... 156 179 200]\n",
      "  [246 243 243 ... 162 178 192]\n",
      "  [246 243 244 ... 166 173 182]]\n",
      "\n",
      " [[102  91  95 ...  71  63  58]\n",
      "  [ 75  72  76 ... 105 111  69]\n",
      "  [ 67  58  59 ... 112 132  72]\n",
      "  ...\n",
      "  [129 123 122 ...  42  59  73]\n",
      "  [133 128 127 ...  44  56  65]\n",
      "  [139 133 132 ...  47  51  57]]\n",
      "\n",
      " [[101  95  97 ...  56  55  55]\n",
      "  [ 68  66  65 ...  71  93  61]\n",
      "  [ 75  60  52 ...  80 105  71]\n",
      "  ...\n",
      "  [ 70  65  65 ...  15  26  36]\n",
      "  [ 74  72  70 ...  14  22  27]\n",
      "  [ 82  78  77 ...  14  17  19]]]\n",
      "[[[159 102 101]\n",
      "  [150  91  95]\n",
      "  [153  95  97]\n",
      "  ...\n",
      "  [ 91  71  56]\n",
      "  [ 74  63  55]\n",
      "  [ 76  58  55]]\n",
      "\n",
      " [[142  75  68]\n",
      "  [146  72  66]\n",
      "  [155  76  65]\n",
      "  ...\n",
      "  [127 105  71]\n",
      "  [122 111  93]\n",
      "  [ 86  69  61]]\n",
      "\n",
      " [[109  67  75]\n",
      "  [ 99  58  60]\n",
      "  [105  59  52]\n",
      "  ...\n",
      "  [137 112  80]\n",
      "  [163 132 105]\n",
      "  [ 93  72  71]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[244 129  70]\n",
      "  [240 123  65]\n",
      "  [241 122  65]\n",
      "  ...\n",
      "  [156  42  15]\n",
      "  [179  59  26]\n",
      "  [200  73  36]]\n",
      "\n",
      " [[246 133  74]\n",
      "  [243 128  72]\n",
      "  [243 127  70]\n",
      "  ...\n",
      "  [162  44  14]\n",
      "  [178  56  22]\n",
      "  [192  65  27]]\n",
      "\n",
      " [[246 139  82]\n",
      "  [243 133  78]\n",
      "  [244 132  77]\n",
      "  ...\n",
      "  [166  47  14]\n",
      "  [173  51  17]\n",
      "  [182  57  19]]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#数据查看\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "a = batch_1['data']\n",
    "imgs = a[5, :].reshape([3, 32, 32])\n",
    "print(imgs)\n",
    "img = np.stack((imgs[0, :, :], imgs[1, :, :], imgs[2, :, :]), 2)\n",
    "r = imgs[0, :, :]\n",
    "g = imgs[1, :, :]\n",
    "b = imgs[2, :, :]\n",
    "print(img)\n",
    "#print(img.shape)\n",
    "#pic = Image.merge('RGB',(r,g,b))\n",
    "plt.imshow(r)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3072)\n",
      "dict_keys(['batch_label', 'labels', 'data', 'filenames'])\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as plt\n",
    "def load(filename):\n",
    "\n",
    "    with open(filename, 'rb') as fo:\n",
    "\n",
    "        data = pickle.load(fo, encoding='latin1')\n",
    "\n",
    "    return data\n",
    "fil = 'E:\\Download\\DigitalImage\\cifar-10-batches-py\\data_batch_1'\n",
    "batch_1 = load(fil)\n",
    "print(batch_1['data'].shape)\n",
    "print(batch_1.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOF while scanning triple-quoted string literal (<ipython-input-7-daf1fc5163f1>, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-7-daf1fc5163f1>\"\u001b[1;36m, line \u001b[1;32m14\u001b[0m\n\u001b[1;33m    print(1)\u001b[0m\n\u001b[1;37m            \n^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "batch1 = []\n",
    "#batch1.extend([1])\n",
    "print(type(batch1))\n",
    "print(batch1)\n",
    "batch1.extend(batch_1['data'])\n",
    "batch1.extend(batch_1['labels'])\n",
    "#batch1 = np.array(batch1)\n",
    "print(batch1[0].shape)\n",
    "batch_1 = transform(batch1)\n",
    "print(batch_1)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "torch.Size([10000, 3, 32, 32])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([10000, 3, 32, 32])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([10000, 3, 32, 32])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([10000, 3, 32, 32])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([10000, 3, 32, 32])\n",
      "<class 'torch.Tensor'>\n",
      "[(tensor([[[[158., 159., 165.,  ..., 137., 126., 116.],\n",
      "          [152., 151., 159.,  ..., 136., 125., 119.],\n",
      "          [151., 151., 158.,  ..., 139., 130., 120.],\n",
      "          ...,\n",
      "          [ 68.,  42.,  31.,  ...,  38.,  13.,  40.],\n",
      "          [ 61.,  49.,  35.,  ...,  26.,  29.,  20.],\n",
      "          [ 54.,  56.,  45.,  ...,  24.,  34.,  21.]],\n",
      "\n",
      "         [[112., 111., 116.,  ...,  95.,  91.,  85.],\n",
      "          [112., 110., 114.,  ...,  95.,  91.,  88.],\n",
      "          [110., 109., 111.,  ...,  98.,  95.,  89.],\n",
      "          ...,\n",
      "          [124., 100.,  88.,  ...,  97.,  64.,  85.],\n",
      "          [116., 102.,  85.,  ...,  82.,  82.,  64.],\n",
      "          [107., 105.,  89.,  ...,  77.,  84.,  67.]],\n",
      "\n",
      "         [[ 49.,  47.,  51.,  ...,  36.,  36.,  33.],\n",
      "          [ 51.,  40.,  45.,  ...,  31.,  32.,  34.],\n",
      "          [ 47.,  33.,  36.,  ...,  34.,  34.,  33.],\n",
      "          ...,\n",
      "          [177., 148., 137.,  ..., 146., 108., 127.],\n",
      "          [168., 148., 132.,  ..., 130., 126., 107.],\n",
      "          [160., 149., 132.,  ..., 124., 129., 110.]]],\n",
      "\n",
      "\n",
      "        [[[235., 231., 232.,  ..., 233., 233., 232.],\n",
      "          [238., 235., 235.,  ..., 236., 236., 235.],\n",
      "          [237., 234., 234.,  ..., 235., 235., 234.],\n",
      "          ...,\n",
      "          [ 87.,  43.,  19.,  ..., 169., 182., 188.],\n",
      "          [ 82.,  46.,  36.,  ..., 174., 185., 187.],\n",
      "          [ 85.,  62.,  58.,  ..., 168., 180., 186.]],\n",
      "\n",
      "         [[235., 231., 232.,  ..., 233., 233., 232.],\n",
      "          [238., 235., 235.,  ..., 236., 236., 235.],\n",
      "          [237., 234., 234.,  ..., 235., 235., 234.],\n",
      "          ...,\n",
      "          [ 99.,  51.,  23.,  ..., 184., 197., 202.],\n",
      "          [ 96.,  57.,  44.,  ..., 189., 200., 202.],\n",
      "          [101.,  75.,  67.,  ..., 183., 195., 200.]],\n",
      "\n",
      "         [[235., 231., 232.,  ..., 233., 233., 232.],\n",
      "          [238., 235., 235.,  ..., 236., 236., 235.],\n",
      "          [237., 234., 234.,  ..., 235., 235., 234.],\n",
      "          ...,\n",
      "          [ 89.,  37.,  11.,  ..., 179., 193., 201.],\n",
      "          [ 82.,  36.,  22.,  ..., 183., 196., 200.],\n",
      "          [ 83.,  48.,  38.,  ..., 178., 191., 199.]]],\n",
      "\n",
      "\n",
      "        [[[158., 158., 139.,  ..., 228., 237., 238.],\n",
      "          [170., 172., 151.,  ..., 232., 246., 246.],\n",
      "          [174., 176., 157.,  ..., 230., 250., 245.],\n",
      "          ...,\n",
      "          [ 31.,  30.,  26.,  ...,  37.,   9.,   4.],\n",
      "          [ 23.,  27.,  25.,  ...,  19.,   4.,   5.],\n",
      "          [ 28.,  30.,  32.,  ...,   5.,   4.,   7.]],\n",
      "\n",
      "         [[190., 187., 166.,  ..., 231., 239., 241.],\n",
      "          [200., 199., 176.,  ..., 232., 246., 247.],\n",
      "          [201., 200., 179.,  ..., 229., 249., 244.],\n",
      "          ...,\n",
      "          [ 40.,  39.,  35.,  ...,  40.,  13.,   7.],\n",
      "          [ 34.,  38.,  36.,  ...,  20.,   6.,   7.],\n",
      "          [ 41.,  43.,  45.,  ...,   6.,   5.,   8.]],\n",
      "\n",
      "         [[222., 218., 194.,  ..., 234., 243., 246.],\n",
      "          [229., 226., 201.,  ..., 236., 250., 251.],\n",
      "          [225., 222., 199.,  ..., 232., 251., 247.],\n",
      "          ...,\n",
      "          [ 45.,  44.,  40.,  ...,  46.,  14.,   5.],\n",
      "          [ 39.,  43.,  41.,  ...,  24.,   3.,   3.],\n",
      "          [ 47.,  50.,  52.,  ...,   8.,   3.,   7.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 20.,  19.,  15.,  ...,  10.,  12.,  13.],\n",
      "          [ 21.,  20.,  18.,  ...,  10.,  10.,  12.],\n",
      "          [ 21.,  21.,  20.,  ...,  12.,  12.,  13.],\n",
      "          ...,\n",
      "          [ 33.,  34.,  34.,  ...,  28.,  29.,  23.],\n",
      "          [ 33.,  34.,  34.,  ...,  27.,  27.,  25.],\n",
      "          [ 31.,  32.,  33.,  ...,  24.,  26.,  25.]],\n",
      "\n",
      "         [[ 15.,  14.,  14.,  ...,   9.,  11.,  12.],\n",
      "          [ 16.,  16.,  17.,  ...,   9.,   9.,  11.],\n",
      "          [ 16.,  17.,  18.,  ...,  11.,  11.,  12.],\n",
      "          ...,\n",
      "          [ 25.,  26.,  26.,  ...,  25.,  25.,  20.],\n",
      "          [ 25.,  26.,  26.,  ...,  24.,  24.,  22.],\n",
      "          [ 23.,  24.,  25.,  ...,  23.,  23.,  20.]],\n",
      "\n",
      "         [[ 12.,  11.,  11.,  ...,   7.,   9.,  10.],\n",
      "          [ 13.,  13.,  12.,  ...,   7.,   7.,   9.],\n",
      "          [ 13.,  12.,  11.,  ...,   9.,   9.,  10.],\n",
      "          ...,\n",
      "          [ 13.,  15.,  15.,  ...,  52.,  58.,  42.],\n",
      "          [ 14.,  15.,  15.,  ...,  52.,  56.,  47.],\n",
      "          [ 12.,  13.,  14.,  ...,  50.,  53.,  47.]]],\n",
      "\n",
      "\n",
      "        [[[ 25.,  15.,  23.,  ...,  61.,  92.,  75.],\n",
      "          [ 12.,  20.,  24.,  ..., 115., 149., 104.],\n",
      "          [ 12.,  15.,  34.,  ..., 154., 157., 116.],\n",
      "          ...,\n",
      "          [100., 103., 104.,  ...,  97.,  98.,  91.],\n",
      "          [103., 104., 107.,  ..., 101.,  99.,  92.],\n",
      "          [ 95.,  95., 101.,  ...,  93.,  95.,  92.]],\n",
      "\n",
      "         [[ 40.,  36.,  41.,  ...,  82., 113.,  89.],\n",
      "          [ 25.,  37.,  36.,  ..., 134., 168., 117.],\n",
      "          [ 25.,  29.,  40.,  ..., 172., 175., 129.],\n",
      "          ...,\n",
      "          [129., 132., 134.,  ..., 128., 126., 121.],\n",
      "          [132., 131., 135.,  ..., 132., 127., 121.],\n",
      "          [126., 123., 128.,  ..., 124., 123., 120.]],\n",
      "\n",
      "         [[ 12.,   3.,  18.,  ...,  78., 112.,  92.],\n",
      "          [  6.,   7.,  15.,  ..., 138., 177., 131.],\n",
      "          [ 11.,   6.,  24.,  ..., 182., 192., 151.],\n",
      "          ...,\n",
      "          [ 81.,  84.,  86.,  ...,  84.,  84.,  79.],\n",
      "          [ 83.,  83.,  87.,  ...,  87.,  84.,  79.],\n",
      "          [ 78.,  76.,  81.,  ...,  80.,  81.,  80.]]],\n",
      "\n",
      "\n",
      "        [[[ 73.,  98.,  99.,  ..., 135., 135., 203.],\n",
      "          [ 69.,  84.,  68.,  ...,  85.,  71., 120.],\n",
      "          [ 69.,  90.,  62.,  ...,  74.,  53.,  62.],\n",
      "          ...,\n",
      "          [123., 132., 129.,  ..., 108.,  62.,  27.],\n",
      "          [115., 123., 129.,  ..., 115.,  66.,  27.],\n",
      "          [116., 121., 129.,  ..., 116.,  68.,  27.]],\n",
      "\n",
      "         [[ 78., 103., 106.,  ..., 150., 149., 215.],\n",
      "          [ 73.,  89.,  75.,  ...,  95.,  82., 133.],\n",
      "          [ 73.,  95.,  71.,  ...,  81.,  62.,  74.],\n",
      "          ...,\n",
      "          [128., 132., 128.,  ..., 107.,  60.,  27.],\n",
      "          [121., 124., 126.,  ..., 116.,  65.,  27.],\n",
      "          [120., 122., 128.,  ..., 115.,  65.,  26.]],\n",
      "\n",
      "         [[ 75., 113., 114.,  ..., 152., 154., 223.],\n",
      "          [ 70.,  97.,  81.,  ...,  89.,  80., 135.],\n",
      "          [ 70., 100.,  74.,  ...,  70.,  54.,  69.],\n",
      "          ...,\n",
      "          [ 96., 102., 100.,  ...,  88.,  55.,  28.],\n",
      "          [ 91.,  95.,  99.,  ...,  94.,  59.,  27.],\n",
      "          [ 90.,  94., 101.,  ...,  94.,  58.,  26.]]]]), tensor([3, 8, 8,  ..., 5, 1, 7]))]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from  torchvision  import datasets,transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "import numpy as plt\n",
    "# 数据加载预处理\n",
    "#def load(filename):\n",
    "\n",
    "#    with open(filename, 'rb') as fo:\n",
    "\n",
    " #       data = pickle.load(fo, encoding='latin1')\n",
    "def load(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "fil_1 = 'E:\\Download\\DigitalImage\\cifar-10-batches-py\\data_batch_1'\n",
    "fil_2 = 'E:\\Download\\DigitalImage\\cifar-10-batches-py\\data_batch_2'\n",
    "fil_3 = 'E:\\Download\\DigitalImage\\cifar-10-batches-py\\data_batch_3'\n",
    "fil_4 = 'E:\\Download\\DigitalImage\\cifar-10-batches-py\\data_batch_4'\n",
    "fil_5 = 'E:\\Download\\DigitalImage\\cifar-10-batches-py\\data_batch_5'\n",
    "fil_6 = 'E:\\Download\\DigitalImage\\cifar-10-batches-py\\\\test_batch_1'\n",
    "\n",
    "path = [fil_1,fil_2,fil_3,fil_4,fil_5,fil_6]\n",
    "train_data = []\n",
    "test_data = []\n",
    "for i in range(len(path)):\n",
    "    if i != len(path)-1:\n",
    "        datas = load(path[i])\n",
    "        #print(datas.keys())\n",
    "        a = datas[b'data'].reshape(10000,3,32,32)\n",
    "       # c = torch.from_numpy(a)\n",
    "       # print(type(a))\n",
    "        #print(a.shape)\n",
    "        train_data.append((torch.FloatTensor(a),torch.LongTensor(datas[b'labels'])))\n",
    "        print()\n",
    "    else:\n",
    "        datas = load(path[i])\n",
    "        test_data = [(torch.FloatTensor(datas[b'data'].reshape(10000,3,32,32)),torch.LongTensor(datas[b'labels']))]\n",
    "#train_batch_1 = load(fil_1)\n",
    "#train_batch_2 = load(fil_2)\n",
    "#train_batch_3 = load(fil_3)\n",
    "#train_batch_4 = load(fil_4)\n",
    "#train_batch_5 = load(fil_5)\n",
    "#test_batch  =  load(fil_6)\n",
    "#data_1 = (batch_1['data'].reshape(10000,3,32,32),batch_1['labels'])\n",
    "#print(data_1.shape)\n",
    "#data_1 = torch.tensor(data_1)\n",
    "#print(data_1)\n",
    "for data,label in train_data:\n",
    "    print(data.shape)\n",
    "    print(type(data))\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0\tbatch:0\tloss:2.1763486862182617\n",
      "epoch:0\tbatch:1\tloss:1.8485407829284668\n",
      "epoch:0\tbatch:2\tloss:1.8671174049377441\n",
      "epoch:0\tbatch:3\tloss:1.8870524168014526\n",
      "epoch:0\tbatch:4\tloss:1.9330265522003174\n",
      "epoch:0\ttest_data_loss:0.017911282896995544\tAccurate36.050000%\n",
      "epoch:1\tbatch:0\tloss:1.8310177326202393\n",
      "epoch:1\tbatch:1\tloss:1.6556342840194702\n",
      "epoch:1\tbatch:2\tloss:1.5648118257522583\n",
      "epoch:1\tbatch:3\tloss:1.6772332191467285\n",
      "epoch:1\tbatch:4\tloss:1.8390121459960938\n",
      "epoch:1\ttest_data_loss:0.01690780953168869\tAccurate40.180000%\n",
      "epoch:2\tbatch:0\tloss:1.6617430448532104\n",
      "epoch:2\tbatch:1\tloss:1.6150680780410767\n",
      "epoch:2\tbatch:2\tloss:1.4591856002807617\n",
      "epoch:2\tbatch:3\tloss:1.5646525621414185\n",
      "epoch:2\tbatch:4\tloss:1.7958917617797852\n",
      "epoch:2\ttest_data_loss:0.01627845757007599\tAccurate42.370000%\n",
      "epoch:3\tbatch:0\tloss:1.578587532043457\n",
      "epoch:3\tbatch:1\tloss:1.5681748390197754\n",
      "epoch:3\tbatch:2\tloss:1.4131228923797607\n",
      "epoch:3\tbatch:3\tloss:1.489415168762207\n",
      "epoch:3\tbatch:4\tloss:1.7504119873046875\n",
      "epoch:3\ttest_data_loss:0.01585704526901245\tAccurate43.700000%\n",
      "epoch:4\tbatch:0\tloss:1.5407977104187012\n",
      "epoch:4\tbatch:1\tloss:1.5327751636505127\n",
      "epoch:4\tbatch:2\tloss:1.3862621784210205\n",
      "epoch:4\tbatch:3\tloss:1.4344329833984375\n",
      "epoch:4\tbatch:4\tloss:1.6997625827789307\n",
      "epoch:4\ttest_data_loss:0.015395513820648193\tAccurate45.150000%\n",
      "epoch:5\tbatch:0\tloss:1.5082505941390991\n",
      "epoch:5\tbatch:1\tloss:1.520317554473877\n",
      "epoch:5\tbatch:2\tloss:1.3617457151412964\n",
      "epoch:5\tbatch:3\tloss:1.3905024528503418\n",
      "epoch:5\tbatch:4\tloss:1.649784803390503\n",
      "epoch:5\ttest_data_loss:0.015025948679447175\tAccurate46.260000%\n",
      "epoch:6\tbatch:0\tloss:1.4764683246612549\n",
      "epoch:6\tbatch:1\tloss:1.4926671981811523\n",
      "epoch:6\tbatch:2\tloss:1.3316032886505127\n",
      "epoch:6\tbatch:3\tloss:1.3512217998504639\n",
      "epoch:6\tbatch:4\tloss:1.6095126867294312\n",
      "epoch:6\ttest_data_loss:0.014772102546691895\tAccurate47.390000%\n",
      "epoch:7\tbatch:0\tloss:1.454451560974121\n",
      "epoch:7\tbatch:1\tloss:1.4697648286819458\n",
      "epoch:7\tbatch:2\tloss:1.3248602151870728\n",
      "epoch:7\tbatch:3\tloss:1.318414568901062\n",
      "epoch:7\tbatch:4\tloss:1.5752568244934082\n",
      "epoch:7\ttest_data_loss:0.014576126658916473\tAccurate48.030000%\n",
      "epoch:8\tbatch:0\tloss:1.4270124435424805\n",
      "epoch:8\tbatch:1\tloss:1.4474483728408813\n",
      "epoch:8\tbatch:2\tloss:1.3211431503295898\n",
      "epoch:8\tbatch:3\tloss:1.2955034971237183\n",
      "epoch:8\tbatch:4\tloss:1.561460256576538\n",
      "epoch:8\ttest_data_loss:0.014510756587982178\tAccurate48.240000%\n",
      "epoch:9\tbatch:0\tloss:1.399457573890686\n",
      "epoch:9\tbatch:1\tloss:1.4223369359970093\n",
      "epoch:9\tbatch:2\tloss:1.3062889575958252\n",
      "epoch:9\tbatch:3\tloss:1.2729438543319702\n",
      "epoch:9\tbatch:4\tloss:1.5518829822540283\n",
      "epoch:9\ttest_data_loss:0.014557824647426606\tAccurate48.320000%\n",
      "epoch:10\tbatch:0\tloss:1.3641740083694458\n",
      "epoch:10\tbatch:1\tloss:1.3875764608383179\n",
      "epoch:10\tbatch:2\tloss:1.3025227785110474\n",
      "epoch:10\tbatch:3\tloss:1.2468807697296143\n",
      "epoch:10\tbatch:4\tloss:1.5115150213241577\n",
      "epoch:10\ttest_data_loss:0.014227166616916656\tAccurate49.220000%\n",
      "epoch:11\tbatch:0\tloss:1.3503832817077637\n",
      "epoch:11\tbatch:1\tloss:1.3648884296417236\n",
      "epoch:11\tbatch:2\tloss:1.2871862649917603\n",
      "epoch:11\tbatch:3\tloss:1.2195641994476318\n",
      "epoch:11\tbatch:4\tloss:1.492020845413208\n",
      "epoch:11\ttest_data_loss:0.014081847751140594\tAccurate49.800000%\n",
      "epoch:12\tbatch:0\tloss:1.3301435708999634\n",
      "epoch:12\tbatch:1\tloss:1.34531569480896\n",
      "epoch:12\tbatch:2\tloss:1.2827187776565552\n",
      "epoch:12\tbatch:3\tloss:1.2025625705718994\n",
      "epoch:12\tbatch:4\tloss:1.4770184755325317\n",
      "epoch:12\ttest_data_loss:0.013916493248939513\tAccurate50.580000%\n",
      "epoch:13\tbatch:0\tloss:1.3146061897277832\n",
      "epoch:13\tbatch:1\tloss:1.3243380784988403\n",
      "epoch:13\tbatch:2\tloss:1.2634878158569336\n",
      "epoch:13\tbatch:3\tloss:1.18169367313385\n",
      "epoch:13\tbatch:4\tloss:1.4633888006210327\n",
      "epoch:13\ttest_data_loss:0.013972422003746033\tAccurate50.270000%\n",
      "epoch:14\tbatch:0\tloss:1.3072998523712158\n",
      "epoch:14\tbatch:1\tloss:1.319836139678955\n",
      "epoch:14\tbatch:2\tloss:1.2426447868347168\n",
      "epoch:14\tbatch:3\tloss:1.1691384315490723\n",
      "epoch:14\tbatch:4\tloss:1.443387508392334\n",
      "epoch:14\ttest_data_loss:0.013678255820274352\tAccurate51.560000%\n",
      "epoch:15\tbatch:0\tloss:1.296415090560913\n",
      "epoch:15\tbatch:1\tloss:1.3018113374710083\n",
      "epoch:15\tbatch:2\tloss:1.2236725091934204\n",
      "epoch:15\tbatch:3\tloss:1.1569795608520508\n",
      "epoch:15\tbatch:4\tloss:1.4256402254104614\n",
      "epoch:15\ttest_data_loss:0.013456743252277375\tAccurate52.280000%\n",
      "epoch:16\tbatch:0\tloss:1.3056328296661377\n",
      "epoch:16\tbatch:1\tloss:1.285027027130127\n",
      "epoch:16\tbatch:2\tloss:1.213087797164917\n",
      "epoch:16\tbatch:3\tloss:1.1255110502243042\n",
      "epoch:16\tbatch:4\tloss:1.4150794744491577\n",
      "epoch:16\ttest_data_loss:0.013432854449748993\tAccurate52.480000%\n",
      "epoch:17\tbatch:0\tloss:1.286566972732544\n",
      "epoch:17\tbatch:1\tloss:1.273400902748108\n",
      "epoch:17\tbatch:2\tloss:1.1688098907470703\n",
      "epoch:17\tbatch:3\tloss:1.1039488315582275\n",
      "epoch:17\tbatch:4\tloss:1.403935432434082\n",
      "epoch:17\ttest_data_loss:0.013373901331424713\tAccurate52.670000%\n",
      "epoch:18\tbatch:0\tloss:1.2652451992034912\n",
      "epoch:18\tbatch:1\tloss:1.2678509950637817\n",
      "epoch:18\tbatch:2\tloss:1.1503956317901611\n",
      "epoch:18\tbatch:3\tloss:1.1067581176757812\n",
      "epoch:18\tbatch:4\tloss:1.3943153619766235\n",
      "epoch:18\ttest_data_loss:0.013238057947158814\tAccurate53.140000%\n",
      "epoch:19\tbatch:0\tloss:1.249767780303955\n",
      "epoch:19\tbatch:1\tloss:1.2521820068359375\n",
      "epoch:19\tbatch:2\tloss:1.1296790838241577\n",
      "epoch:19\tbatch:3\tloss:1.0934704542160034\n",
      "epoch:19\tbatch:4\tloss:1.3765597343444824\n",
      "epoch:19\ttest_data_loss:0.013092611998319625\tAccurate53.710000%\n",
      "epoch:20\tbatch:0\tloss:1.246160626411438\n",
      "epoch:20\tbatch:1\tloss:1.2418464422225952\n",
      "epoch:20\tbatch:2\tloss:1.112160563468933\n",
      "epoch:20\tbatch:3\tloss:1.0844348669052124\n",
      "epoch:20\tbatch:4\tloss:1.375006079673767\n",
      "epoch:20\ttest_data_loss:0.01314392517209053\tAccurate53.820000%\n",
      "epoch:21\tbatch:0\tloss:1.230027675628662\n",
      "epoch:21\tbatch:1\tloss:1.2319188117980957\n",
      "epoch:21\tbatch:2\tloss:1.1040558815002441\n",
      "epoch:21\tbatch:3\tloss:1.0825090408325195\n",
      "epoch:21\tbatch:4\tloss:1.361841082572937\n",
      "epoch:21\ttest_data_loss:0.013016697251796723\tAccurate54.540000%\n",
      "epoch:22\tbatch:0\tloss:1.2315549850463867\n",
      "epoch:22\tbatch:1\tloss:1.226099967956543\n",
      "epoch:22\tbatch:2\tloss:1.0663682222366333\n",
      "epoch:22\tbatch:3\tloss:1.0613822937011719\n",
      "epoch:22\tbatch:4\tloss:1.3560349941253662\n",
      "epoch:22\ttest_data_loss:0.012939717733860016\tAccurate54.580000%\n",
      "epoch:23\tbatch:0\tloss:1.2108231782913208\n",
      "epoch:23\tbatch:1\tloss:1.211175799369812\n",
      "epoch:23\tbatch:2\tloss:1.049925684928894\n",
      "epoch:23\tbatch:3\tloss:1.0554488897323608\n",
      "epoch:23\tbatch:4\tloss:1.3443384170532227\n",
      "epoch:23\ttest_data_loss:0.012848593050241471\tAccurate55.140000%\n",
      "epoch:24\tbatch:0\tloss:1.1964356899261475\n",
      "epoch:24\tbatch:1\tloss:1.1944196224212646\n",
      "epoch:24\tbatch:2\tloss:1.056996464729309\n",
      "epoch:24\tbatch:3\tloss:1.0372012853622437\n",
      "epoch:24\tbatch:4\tloss:1.3305768966674805\n",
      "epoch:24\ttest_data_loss:0.01277999370098114\tAccurate55.210000%\n",
      "epoch:25\tbatch:0\tloss:1.1803444623947144\n",
      "epoch:25\tbatch:1\tloss:1.180546522140503\n",
      "epoch:25\tbatch:2\tloss:1.0308318138122559\n",
      "epoch:25\tbatch:3\tloss:1.032820463180542\n",
      "epoch:25\tbatch:4\tloss:1.3212608098983765\n",
      "epoch:25\ttest_data_loss:0.012731006252765655\tAccurate55.280000%\n",
      "epoch:26\tbatch:0\tloss:1.1709498167037964\n",
      "epoch:26\tbatch:1\tloss:1.1684887409210205\n",
      "epoch:26\tbatch:2\tloss:1.0190114974975586\n",
      "epoch:26\tbatch:3\tloss:1.0146610736846924\n",
      "epoch:26\tbatch:4\tloss:1.3171403408050537\n",
      "epoch:26\ttest_data_loss:0.012678796166181564\tAccurate55.680000%\n",
      "epoch:27\tbatch:0\tloss:1.15721595287323\n",
      "epoch:27\tbatch:1\tloss:1.1603751182556152\n",
      "epoch:27\tbatch:2\tloss:0.9998421669006348\n",
      "epoch:27\tbatch:3\tloss:1.003671646118164\n",
      "epoch:27\tbatch:4\tloss:1.3122105598449707\n",
      "epoch:27\ttest_data_loss:0.012625258141756059\tAccurate55.700000%\n",
      "epoch:28\tbatch:0\tloss:1.147373080253601\n",
      "epoch:28\tbatch:1\tloss:1.143071174621582\n",
      "epoch:28\tbatch:2\tloss:0.9861371517181396\n",
      "epoch:28\tbatch:3\tloss:0.9906672835350037\n",
      "epoch:28\tbatch:4\tloss:1.300931692123413\n",
      "epoch:28\ttest_data_loss:0.0126634123980999\tAccurate55.890000%\n",
      "epoch:29\tbatch:0\tloss:1.134721279144287\n",
      "epoch:29\tbatch:1\tloss:1.1332404613494873\n",
      "epoch:29\tbatch:2\tloss:0.9739859104156494\n",
      "epoch:29\tbatch:3\tloss:0.9740185737609863\n",
      "epoch:29\tbatch:4\tloss:1.2824451923370361\n",
      "epoch:29\ttest_data_loss:0.012466204243898391\tAccurate56.550000%\n",
      "epoch:30\tbatch:0\tloss:1.1220331192016602\n",
      "epoch:30\tbatch:1\tloss:1.129509687423706\n",
      "epoch:30\tbatch:2\tloss:0.9555858373641968\n",
      "epoch:30\tbatch:3\tloss:0.9615256786346436\n",
      "epoch:30\tbatch:4\tloss:1.2834577560424805\n",
      "epoch:30\ttest_data_loss:0.012503732699155808\tAccurate56.550000%\n",
      "epoch:31\tbatch:0\tloss:1.116666316986084\n",
      "epoch:31\tbatch:1\tloss:1.1220072507858276\n",
      "epoch:31\tbatch:2\tloss:0.9467626810073853\n",
      "epoch:31\tbatch:3\tloss:0.9558188915252686\n",
      "epoch:31\tbatch:4\tloss:1.2670265436172485\n",
      "epoch:31\ttest_data_loss:0.012409158754348755\tAccurate56.860000%\n",
      "epoch:32\tbatch:0\tloss:1.10989248752594\n",
      "epoch:32\tbatch:1\tloss:1.105167031288147\n",
      "epoch:32\tbatch:2\tloss:0.9359852075576782\n",
      "epoch:32\tbatch:3\tloss:0.9423297047615051\n",
      "epoch:32\tbatch:4\tloss:1.2532808780670166\n",
      "epoch:32\ttest_data_loss:0.012353265279531478\tAccurate57.120000%\n",
      "epoch:33\tbatch:0\tloss:1.0959490537643433\n",
      "epoch:33\tbatch:1\tloss:1.0946422815322876\n",
      "epoch:33\tbatch:2\tloss:0.9063156247138977\n",
      "epoch:33\tbatch:3\tloss:0.9346637725830078\n",
      "epoch:33\tbatch:4\tloss:1.247786045074463\n",
      "epoch:33\ttest_data_loss:0.012389025342464447\tAccurate56.790000%\n",
      "epoch:34\tbatch:0\tloss:1.0865745544433594\n",
      "epoch:34\tbatch:1\tloss:1.0887271165847778\n",
      "epoch:34\tbatch:2\tloss:0.8950309753417969\n",
      "epoch:34\tbatch:3\tloss:0.9248678088188171\n",
      "epoch:34\tbatch:4\tloss:1.2340625524520874\n",
      "epoch:34\ttest_data_loss:0.012240403681993485\tAccurate57.470000%\n",
      "epoch:35\tbatch:0\tloss:1.0783060789108276\n",
      "epoch:35\tbatch:1\tloss:1.0845303535461426\n",
      "epoch:35\tbatch:2\tloss:0.8918731808662415\n",
      "epoch:35\tbatch:3\tloss:0.9202204346656799\n",
      "epoch:35\tbatch:4\tloss:1.2402079105377197\n",
      "epoch:35\ttest_data_loss:0.012367400372028351\tAccurate57.160000%\n",
      "epoch:36\tbatch:0\tloss:1.0713376998901367\n",
      "epoch:36\tbatch:1\tloss:1.0743495225906372\n",
      "epoch:36\tbatch:2\tloss:0.8726376295089722\n",
      "epoch:36\tbatch:3\tloss:0.9055319428443909\n",
      "epoch:36\tbatch:4\tloss:1.2279491424560547\n",
      "epoch:36\ttest_data_loss:0.01228697457909584\tAccurate57.530000%\n",
      "epoch:37\tbatch:0\tloss:1.063300371170044\n",
      "epoch:37\tbatch:1\tloss:1.071332573890686\n",
      "epoch:37\tbatch:2\tloss:0.8584305644035339\n",
      "epoch:37\tbatch:3\tloss:0.909121572971344\n",
      "epoch:37\tbatch:4\tloss:1.237462043762207\n",
      "epoch:37\ttest_data_loss:0.012473661673069\tAccurate56.820000%\n",
      "epoch:38\tbatch:0\tloss:1.0622907876968384\n",
      "epoch:38\tbatch:1\tloss:1.0578161478042603\n",
      "epoch:38\tbatch:2\tloss:0.8334359526634216\n",
      "epoch:38\tbatch:3\tloss:0.898313581943512\n",
      "epoch:38\tbatch:4\tloss:1.1832588911056519\n",
      "epoch:38\ttest_data_loss:0.012111672431230545\tAccurate58.120000%\n",
      "epoch:39\tbatch:0\tloss:1.053490161895752\n",
      "epoch:39\tbatch:1\tloss:1.0428667068481445\n",
      "epoch:39\tbatch:2\tloss:0.8298377394676208\n",
      "epoch:39\tbatch:3\tloss:0.8762632012367249\n",
      "epoch:39\tbatch:4\tloss:1.17948579788208\n",
      "epoch:39\ttest_data_loss:0.012120541250705719\tAccurate58.140000%\n",
      "epoch:40\tbatch:0\tloss:1.0463067293167114\n",
      "epoch:40\tbatch:1\tloss:1.0299921035766602\n",
      "epoch:40\tbatch:2\tloss:0.822319507598877\n",
      "epoch:40\tbatch:3\tloss:0.8699830770492554\n",
      "epoch:40\tbatch:4\tloss:1.1946812868118286\n",
      "epoch:40\ttest_data_loss:0.012327069675922394\tAccurate57.490000%\n",
      "epoch:41\tbatch:0\tloss:1.0353924036026\n",
      "epoch:41\tbatch:1\tloss:1.0170131921768188\n",
      "epoch:41\tbatch:2\tloss:0.8004801273345947\n",
      "epoch:41\tbatch:3\tloss:0.8667176961898804\n",
      "epoch:41\tbatch:4\tloss:1.1923938989639282\n",
      "epoch:41\ttest_data_loss:0.012430083268880844\tAccurate57.260000%\n",
      "epoch:42\tbatch:0\tloss:1.0293288230895996\n",
      "epoch:42\tbatch:1\tloss:1.0096769332885742\n",
      "epoch:42\tbatch:2\tloss:0.7901542782783508\n",
      "epoch:42\tbatch:3\tloss:0.8506443500518799\n",
      "epoch:42\tbatch:4\tloss:1.1419620513916016\n",
      "epoch:42\ttest_data_loss:0.01194839488863945\tAccurate58.890000%\n",
      "epoch:43\tbatch:0\tloss:1.0246968269348145\n",
      "epoch:43\tbatch:1\tloss:1.0024477243423462\n",
      "epoch:43\tbatch:2\tloss:0.7936599850654602\n",
      "epoch:43\tbatch:3\tloss:0.8373702168464661\n",
      "epoch:43\tbatch:4\tloss:1.1571813821792603\n",
      "epoch:43\ttest_data_loss:0.012122386461496354\tAccurate58.550000%\n",
      "epoch:44\tbatch:0\tloss:1.0186289548873901\n",
      "epoch:44\tbatch:1\tloss:0.9998814463615417\n",
      "epoch:44\tbatch:2\tloss:0.7855499386787415\n",
      "epoch:44\tbatch:3\tloss:0.8292716145515442\n",
      "epoch:44\tbatch:4\tloss:1.1527979373931885\n",
      "epoch:44\ttest_data_loss:0.012184381687641143\tAccurate58.440000%\n",
      "epoch:45\tbatch:0\tloss:1.005703330039978\n",
      "epoch:45\tbatch:1\tloss:0.9859725832939148\n",
      "epoch:45\tbatch:2\tloss:0.7656514048576355\n",
      "epoch:45\tbatch:3\tloss:0.8201987743377686\n",
      "epoch:45\tbatch:4\tloss:1.1292855739593506\n",
      "epoch:45\ttest_data_loss:0.012021716064214706\tAccurate58.920000%\n",
      "epoch:46\tbatch:0\tloss:1.005447268486023\n",
      "epoch:46\tbatch:1\tloss:0.9808069467544556\n",
      "epoch:46\tbatch:2\tloss:0.7645500302314758\n",
      "epoch:46\tbatch:3\tloss:0.8219192624092102\n",
      "epoch:46\tbatch:4\tloss:1.124232292175293\n",
      "epoch:46\ttest_data_loss:0.01202094299197197\tAccurate58.790000%\n",
      "epoch:47\tbatch:0\tloss:0.9986887574195862\n",
      "epoch:47\tbatch:1\tloss:0.9843454957008362\n",
      "epoch:47\tbatch:2\tloss:0.7336840033531189\n",
      "epoch:47\tbatch:3\tloss:0.810841977596283\n",
      "epoch:47\tbatch:4\tloss:1.1182644367218018\n",
      "epoch:47\ttest_data_loss:0.012076971423625946\tAccurate58.770000%\n",
      "epoch:48\tbatch:0\tloss:0.9982472062110901\n",
      "epoch:48\tbatch:1\tloss:0.9766039252281189\n",
      "epoch:48\tbatch:2\tloss:0.7371082901954651\n",
      "epoch:48\tbatch:3\tloss:0.8079491257667542\n",
      "epoch:48\tbatch:4\tloss:1.0969032049179077\n",
      "epoch:48\ttest_data_loss:0.011909782522916794\tAccurate59.150000%\n",
      "epoch:49\tbatch:0\tloss:0.9908055663108826\n",
      "epoch:49\tbatch:1\tloss:0.9768622517585754\n",
      "epoch:49\tbatch:2\tloss:0.7220377326011658\n",
      "epoch:49\tbatch:3\tloss:0.7978006601333618\n",
      "epoch:49\tbatch:4\tloss:1.0883194208145142\n",
      "epoch:49\ttest_data_loss:0.011909426361322403\tAccurate59.320000%\n",
      "epoch:50\tbatch:0\tloss:0.983595073223114\n",
      "epoch:50\tbatch:1\tloss:0.9729110598564148\n",
      "epoch:50\tbatch:2\tloss:0.7186201214790344\n",
      "epoch:50\tbatch:3\tloss:0.7884392738342285\n",
      "epoch:50\tbatch:4\tloss:1.0851426124572754\n",
      "epoch:50\ttest_data_loss:0.011971778297424317\tAccurate59.150000%\n",
      "epoch:51\tbatch:0\tloss:0.9790523052215576\n",
      "epoch:51\tbatch:1\tloss:0.9831700325012207\n",
      "epoch:51\tbatch:2\tloss:0.7067458629608154\n",
      "epoch:51\tbatch:3\tloss:0.7885497212409973\n",
      "epoch:51\tbatch:4\tloss:1.0863707065582275\n",
      "epoch:51\ttest_data_loss:0.012032448935508727\tAccurate58.950000%\n",
      "epoch:52\tbatch:0\tloss:0.976442277431488\n",
      "epoch:52\tbatch:1\tloss:0.9837910532951355\n",
      "epoch:52\tbatch:2\tloss:0.6970487833023071\n",
      "epoch:52\tbatch:3\tloss:0.79522705078125\n",
      "epoch:52\tbatch:4\tloss:1.0756380558013916\n",
      "epoch:52\ttest_data_loss:0.011955438911914825\tAccurate59.340000%\n",
      "epoch:53\tbatch:0\tloss:0.9686588048934937\n",
      "epoch:53\tbatch:1\tloss:0.9714369773864746\n",
      "epoch:53\tbatch:2\tloss:0.696596622467041\n",
      "epoch:53\tbatch:3\tloss:0.7947900295257568\n",
      "epoch:53\tbatch:4\tloss:1.0634669065475464\n",
      "epoch:53\ttest_data_loss:0.011919073539972305\tAccurate59.490000%\n",
      "epoch:54\tbatch:0\tloss:0.9600600600242615\n",
      "epoch:54\tbatch:1\tloss:0.9552971720695496\n",
      "epoch:54\tbatch:2\tloss:0.6850804090499878\n",
      "epoch:54\tbatch:3\tloss:0.7764192819595337\n",
      "epoch:54\tbatch:4\tloss:1.0798065662384033\n",
      "epoch:54\ttest_data_loss:0.012189370846748352\tAccurate58.750000%\n",
      "epoch:55\tbatch:0\tloss:0.948850691318512\n",
      "epoch:55\tbatch:1\tloss:0.9429957866668701\n",
      "epoch:55\tbatch:2\tloss:0.6748811602592468\n",
      "epoch:55\tbatch:3\tloss:0.7751486301422119\n",
      "epoch:55\tbatch:4\tloss:1.0750495195388794\n",
      "epoch:55\ttest_data_loss:0.012300976008176803\tAccurate58.620000%\n",
      "epoch:56\tbatch:0\tloss:0.9466851949691772\n",
      "epoch:56\tbatch:1\tloss:0.9432587623596191\n",
      "epoch:56\tbatch:2\tloss:0.6735990047454834\n",
      "epoch:56\tbatch:3\tloss:0.751315176486969\n",
      "epoch:56\tbatch:4\tloss:1.0524924993515015\n",
      "epoch:56\ttest_data_loss:0.012020810967683792\tAccurate59.500000%\n",
      "epoch:57\tbatch:0\tloss:0.9404129981994629\n",
      "epoch:57\tbatch:1\tloss:0.939484715461731\n",
      "epoch:57\tbatch:2\tloss:0.6665537357330322\n",
      "epoch:57\tbatch:3\tloss:0.773976743221283\n",
      "epoch:57\tbatch:4\tloss:1.0542845726013184\n",
      "epoch:57\ttest_data_loss:0.012102680951356888\tAccurate59.310000%\n",
      "epoch:58\tbatch:0\tloss:0.9338595867156982\n",
      "epoch:58\tbatch:1\tloss:0.9297202229499817\n",
      "epoch:58\tbatch:2\tloss:0.6513926982879639\n",
      "epoch:58\tbatch:3\tloss:0.7511664628982544\n",
      "epoch:58\tbatch:4\tloss:1.033987045288086\n",
      "epoch:58\ttest_data_loss:0.012076104605197906\tAccurate59.430000%\n",
      "epoch:59\tbatch:0\tloss:0.9271847009658813\n",
      "epoch:59\tbatch:1\tloss:0.9180575609207153\n",
      "epoch:59\tbatch:2\tloss:0.6456846594810486\n",
      "epoch:59\tbatch:3\tloss:0.7758282423019409\n",
      "epoch:59\tbatch:4\tloss:1.0413581132888794\n",
      "epoch:59\ttest_data_loss:0.01211642199754715\tAccurate59.290000%\n",
      "epoch:60\tbatch:0\tloss:0.9270028471946716\n",
      "epoch:60\tbatch:1\tloss:0.9259335994720459\n",
      "epoch:60\tbatch:2\tloss:0.6387282013893127\n",
      "epoch:60\tbatch:3\tloss:0.734138548374176\n",
      "epoch:60\tbatch:4\tloss:1.036148190498352\n",
      "epoch:60\ttest_data_loss:0.012161384063959122\tAccurate59.220000%\n",
      "epoch:61\tbatch:0\tloss:0.9203653931617737\n",
      "epoch:61\tbatch:1\tloss:0.9158979654312134\n",
      "epoch:61\tbatch:2\tloss:0.6304754018783569\n",
      "epoch:61\tbatch:3\tloss:0.7710758447647095\n",
      "epoch:61\tbatch:4\tloss:1.035487413406372\n",
      "epoch:61\ttest_data_loss:0.012326200085878373\tAccurate58.760000%\n",
      "epoch:62\tbatch:0\tloss:0.903017520904541\n",
      "epoch:62\tbatch:1\tloss:0.916846513748169\n",
      "epoch:62\tbatch:2\tloss:0.6255664229393005\n",
      "epoch:62\tbatch:3\tloss:0.7590267062187195\n",
      "epoch:62\tbatch:4\tloss:0.996479868888855\n",
      "epoch:62\ttest_data_loss:0.012058472818136216\tAccurate59.870000%\n",
      "epoch:63\tbatch:0\tloss:0.8996082544326782\n",
      "epoch:63\tbatch:1\tloss:0.9081469774246216\n",
      "epoch:63\tbatch:2\tloss:0.6192362308502197\n",
      "epoch:63\tbatch:3\tloss:0.7516011595726013\n",
      "epoch:63\tbatch:4\tloss:1.0203711986541748\n",
      "epoch:63\ttest_data_loss:0.01221827574968338\tAccurate59.070000%\n",
      "epoch:64\tbatch:0\tloss:0.8907505869865417\n",
      "epoch:64\tbatch:1\tloss:0.9166998267173767\n",
      "epoch:64\tbatch:2\tloss:0.6077508330345154\n",
      "epoch:64\tbatch:3\tloss:0.7394577264785767\n",
      "epoch:64\tbatch:4\tloss:1.0201599597930908\n",
      "epoch:64\ttest_data_loss:0.012330314660072327\tAccurate58.870000%\n",
      "epoch:65\tbatch:0\tloss:0.8966385126113892\n",
      "epoch:65\tbatch:1\tloss:0.8998122215270996\n",
      "epoch:65\tbatch:2\tloss:0.6034379601478577\n",
      "epoch:65\tbatch:3\tloss:0.7274463176727295\n",
      "epoch:65\tbatch:4\tloss:1.005628228187561\n",
      "epoch:65\ttest_data_loss:0.01231836119890213\tAccurate58.830000%\n",
      "epoch:66\tbatch:0\tloss:0.883089005947113\n",
      "epoch:66\tbatch:1\tloss:0.8922118544578552\n",
      "epoch:66\tbatch:2\tloss:0.596132218837738\n",
      "epoch:66\tbatch:3\tloss:0.7443216443061829\n",
      "epoch:66\tbatch:4\tloss:1.0012356042861938\n",
      "epoch:66\ttest_data_loss:0.012521785014867783\tAccurate58.590000%\n",
      "epoch:67\tbatch:0\tloss:0.8771061897277832\n",
      "epoch:67\tbatch:1\tloss:0.8932440876960754\n",
      "epoch:67\tbatch:2\tloss:0.5898717641830444\n",
      "epoch:67\tbatch:3\tloss:0.7238337993621826\n",
      "epoch:67\tbatch:4\tloss:0.99314284324646\n",
      "epoch:67\ttest_data_loss:0.012429105460643769\tAccurate59.000000%\n",
      "epoch:68\tbatch:0\tloss:0.8710014820098877\n",
      "epoch:68\tbatch:1\tloss:0.8868461847305298\n",
      "epoch:68\tbatch:2\tloss:0.591881513595581\n",
      "epoch:68\tbatch:3\tloss:0.7148791551589966\n",
      "epoch:68\tbatch:4\tloss:0.9507726430892944\n",
      "epoch:68\ttest_data_loss:0.012235509532690049\tAccurate59.500000%\n",
      "epoch:69\tbatch:0\tloss:0.875399649143219\n",
      "epoch:69\tbatch:1\tloss:0.882342517375946\n",
      "epoch:69\tbatch:2\tloss:0.5730912089347839\n",
      "epoch:69\tbatch:3\tloss:0.7121666073799133\n",
      "epoch:69\tbatch:4\tloss:0.9842464923858643\n",
      "epoch:69\ttest_data_loss:0.012471738237142562\tAccurate58.800000%\n",
      "epoch:70\tbatch:0\tloss:0.8595896363258362\n",
      "epoch:70\tbatch:1\tloss:0.8784759640693665\n",
      "epoch:70\tbatch:2\tloss:0.5651609897613525\n",
      "epoch:70\tbatch:3\tloss:0.7028424143791199\n",
      "epoch:70\tbatch:4\tloss:0.9836839437484741\n",
      "epoch:70\ttest_data_loss:0.012522421032190322\tAccurate58.720000%\n",
      "epoch:71\tbatch:0\tloss:0.8662053942680359\n",
      "epoch:71\tbatch:1\tloss:0.8788058757781982\n",
      "epoch:71\tbatch:2\tloss:0.5588352084159851\n",
      "epoch:71\tbatch:3\tloss:0.690401017665863\n",
      "epoch:71\tbatch:4\tloss:0.9646252989768982\n",
      "epoch:71\ttest_data_loss:0.012400003510713577\tAccurate59.110000%\n",
      "epoch:72\tbatch:0\tloss:0.8529565334320068\n",
      "epoch:72\tbatch:1\tloss:0.8709671497344971\n",
      "epoch:72\tbatch:2\tloss:0.553376317024231\n",
      "epoch:72\tbatch:3\tloss:0.6751856207847595\n",
      "epoch:72\tbatch:4\tloss:0.9765558838844299\n",
      "epoch:72\ttest_data_loss:0.012685820615291596\tAccurate58.630000%\n",
      "epoch:73\tbatch:0\tloss:0.854845404624939\n",
      "epoch:73\tbatch:1\tloss:0.8709725737571716\n",
      "epoch:73\tbatch:2\tloss:0.5648348331451416\n",
      "epoch:73\tbatch:3\tloss:0.6906089782714844\n",
      "epoch:73\tbatch:4\tloss:0.9492604732513428\n",
      "epoch:73\ttest_data_loss:0.012380959230661391\tAccurate59.420000%\n",
      "epoch:74\tbatch:0\tloss:0.8366735577583313\n",
      "epoch:74\tbatch:1\tloss:0.8609594702720642\n",
      "epoch:74\tbatch:2\tloss:0.5395348072052002\n",
      "epoch:74\tbatch:3\tloss:0.6860594749450684\n",
      "epoch:74\tbatch:4\tloss:0.9336348176002502\n",
      "epoch:74\ttest_data_loss:0.01231137964129448\tAccurate59.590000%\n",
      "epoch:75\tbatch:0\tloss:0.8330693244934082\n",
      "epoch:75\tbatch:1\tloss:0.8502030968666077\n",
      "epoch:75\tbatch:2\tloss:0.5497587323188782\n",
      "epoch:75\tbatch:3\tloss:0.6887615323066711\n",
      "epoch:75\tbatch:4\tloss:0.9692203402519226\n",
      "epoch:75\ttest_data_loss:0.01274453642964363\tAccurate58.550000%\n",
      "epoch:76\tbatch:0\tloss:0.8370388150215149\n",
      "epoch:76\tbatch:1\tloss:0.8443731069564819\n",
      "epoch:76\tbatch:2\tloss:0.5396125316619873\n",
      "epoch:76\tbatch:3\tloss:0.6720179915428162\n",
      "epoch:76\tbatch:4\tloss:0.9343408346176147\n",
      "epoch:76\ttest_data_loss:0.012507897245883942\tAccurate59.250000%\n",
      "epoch:77\tbatch:0\tloss:0.8270650506019592\n",
      "epoch:77\tbatch:1\tloss:0.8446207642555237\n",
      "epoch:77\tbatch:2\tloss:0.5341995358467102\n",
      "epoch:77\tbatch:3\tloss:0.6691818833351135\n",
      "epoch:77\tbatch:4\tloss:0.9361714124679565\n",
      "epoch:77\ttest_data_loss:0.01255682343840599\tAccurate59.200000%\n",
      "epoch:78\tbatch:0\tloss:0.8156286478042603\n",
      "epoch:78\tbatch:1\tloss:0.8541104197502136\n",
      "epoch:78\tbatch:2\tloss:0.5318109393119812\n",
      "epoch:78\tbatch:3\tloss:0.6843156218528748\n",
      "epoch:78\tbatch:4\tloss:0.9118959307670593\n",
      "epoch:78\ttest_data_loss:0.012407086634635925\tAccurate59.480000%\n",
      "epoch:79\tbatch:0\tloss:0.8160406351089478\n",
      "epoch:79\tbatch:1\tloss:0.8300583362579346\n",
      "epoch:79\tbatch:2\tloss:0.5285741686820984\n",
      "epoch:79\tbatch:3\tloss:0.6565198302268982\n",
      "epoch:79\tbatch:4\tloss:0.8986861705780029\n",
      "epoch:79\ttest_data_loss:0.012445626938343049\tAccurate59.570000%\n",
      "epoch:80\tbatch:0\tloss:0.8102062344551086\n",
      "epoch:80\tbatch:1\tloss:0.8347083926200867\n",
      "epoch:80\tbatch:2\tloss:0.5339607000350952\n",
      "epoch:80\tbatch:3\tloss:0.6456961035728455\n",
      "epoch:80\tbatch:4\tloss:0.9030000567436218\n",
      "epoch:80\ttest_data_loss:0.012595359736680984\tAccurate58.940000%\n",
      "epoch:81\tbatch:0\tloss:0.8115819692611694\n",
      "epoch:81\tbatch:1\tloss:0.8459965586662292\n",
      "epoch:81\tbatch:2\tloss:0.5200003981590271\n",
      "epoch:81\tbatch:3\tloss:0.6476116180419922\n",
      "epoch:81\tbatch:4\tloss:0.9068138003349304\n",
      "epoch:81\ttest_data_loss:0.012721691608428955\tAccurate58.970000%\n",
      "epoch:82\tbatch:0\tloss:0.7949211597442627\n",
      "epoch:82\tbatch:1\tloss:0.8297266960144043\n",
      "epoch:82\tbatch:2\tloss:0.5128525495529175\n",
      "epoch:82\tbatch:3\tloss:0.6498642563819885\n",
      "epoch:82\tbatch:4\tloss:0.894875168800354\n",
      "epoch:82\ttest_data_loss:0.012713435411453247\tAccurate59.090000%\n",
      "epoch:83\tbatch:0\tloss:0.791240930557251\n",
      "epoch:83\tbatch:1\tloss:0.8250916004180908\n",
      "epoch:83\tbatch:2\tloss:0.5194141864776611\n",
      "epoch:83\tbatch:3\tloss:0.6340817213058472\n",
      "epoch:83\tbatch:4\tloss:0.8656267523765564\n",
      "epoch:83\ttest_data_loss:0.012319718247652054\tAccurate60.230000%\n",
      "epoch:84\tbatch:0\tloss:0.7851470112800598\n",
      "epoch:84\tbatch:1\tloss:0.8251030445098877\n",
      "epoch:84\tbatch:2\tloss:0.5101059675216675\n",
      "epoch:84\tbatch:3\tloss:0.6454721093177795\n",
      "epoch:84\tbatch:4\tloss:0.8840279579162598\n",
      "epoch:84\ttest_data_loss:0.012764427667856217\tAccurate59.060000%\n",
      "epoch:85\tbatch:0\tloss:0.7791163921356201\n",
      "epoch:85\tbatch:1\tloss:0.8116323947906494\n",
      "epoch:85\tbatch:2\tloss:0.5036025047302246\n",
      "epoch:85\tbatch:3\tloss:0.6301839351654053\n",
      "epoch:85\tbatch:4\tloss:0.879149854183197\n",
      "epoch:85\ttest_data_loss:0.012517074817419052\tAccurate59.660000%\n",
      "epoch:86\tbatch:0\tloss:0.7759548425674438\n",
      "epoch:86\tbatch:1\tloss:0.8047389984130859\n",
      "epoch:86\tbatch:2\tloss:0.502409815788269\n",
      "epoch:86\tbatch:3\tloss:0.6240792870521545\n",
      "epoch:86\tbatch:4\tloss:0.8872179388999939\n",
      "epoch:86\ttest_data_loss:0.012680694687366486\tAccurate59.530000%\n",
      "epoch:87\tbatch:0\tloss:0.7670626640319824\n",
      "epoch:87\tbatch:1\tloss:0.8061250448226929\n",
      "epoch:87\tbatch:2\tloss:0.49632957577705383\n",
      "epoch:87\tbatch:3\tloss:0.6225496530532837\n",
      "epoch:87\tbatch:4\tloss:0.8548753261566162\n",
      "epoch:87\ttest_data_loss:0.012535573565959931\tAccurate59.960000%\n",
      "epoch:88\tbatch:0\tloss:0.7627490162849426\n",
      "epoch:88\tbatch:1\tloss:0.8064558506011963\n",
      "epoch:88\tbatch:2\tloss:0.4960155189037323\n",
      "epoch:88\tbatch:3\tloss:0.6191938519477844\n",
      "epoch:88\tbatch:4\tloss:0.8474365472793579\n",
      "epoch:88\ttest_data_loss:0.012563345158100129\tAccurate60.110000%\n",
      "epoch:89\tbatch:0\tloss:0.7571389675140381\n",
      "epoch:89\tbatch:1\tloss:0.7934638261795044\n",
      "epoch:89\tbatch:2\tloss:0.48885154724121094\n",
      "epoch:89\tbatch:3\tloss:0.6137969493865967\n",
      "epoch:89\tbatch:4\tloss:0.8477094173431396\n",
      "epoch:89\ttest_data_loss:0.012598423415422439\tAccurate59.830000%\n",
      "epoch:90\tbatch:0\tloss:0.7546694874763489\n",
      "epoch:90\tbatch:1\tloss:0.7917743921279907\n",
      "epoch:90\tbatch:2\tloss:0.4976850152015686\n",
      "epoch:90\tbatch:3\tloss:0.5993662476539612\n",
      "epoch:90\tbatch:4\tloss:0.8570490479469299\n",
      "epoch:90\ttest_data_loss:0.012875428235530853\tAccurate59.410000%\n",
      "epoch:91\tbatch:0\tloss:0.7442094683647156\n",
      "epoch:91\tbatch:1\tloss:0.7596681118011475\n",
      "epoch:91\tbatch:2\tloss:0.4806060492992401\n",
      "epoch:91\tbatch:3\tloss:0.6272403597831726\n",
      "epoch:91\tbatch:4\tloss:0.8467599749565125\n",
      "epoch:91\ttest_data_loss:0.012833891832828521\tAccurate59.470000%\n",
      "epoch:92\tbatch:0\tloss:0.7448679208755493\n",
      "epoch:92\tbatch:1\tloss:0.7580040097236633\n",
      "epoch:92\tbatch:2\tloss:0.47535035014152527\n",
      "epoch:92\tbatch:3\tloss:0.5988304018974304\n",
      "epoch:92\tbatch:4\tloss:0.8385698795318604\n",
      "epoch:92\ttest_data_loss:0.012903959184885025\tAccurate59.550000%\n",
      "epoch:93\tbatch:0\tloss:0.735319197177887\n",
      "epoch:93\tbatch:1\tloss:0.7605016827583313\n",
      "epoch:93\tbatch:2\tloss:0.46915584802627563\n",
      "epoch:93\tbatch:3\tloss:0.6321775913238525\n",
      "epoch:93\tbatch:4\tloss:0.8465431928634644\n",
      "epoch:93\ttest_data_loss:0.012943225288391114\tAccurate59.610000%\n",
      "epoch:94\tbatch:0\tloss:0.7304616570472717\n",
      "epoch:94\tbatch:1\tloss:0.7537645101547241\n",
      "epoch:94\tbatch:2\tloss:0.4738635718822479\n",
      "epoch:94\tbatch:3\tloss:0.5927462577819824\n",
      "epoch:94\tbatch:4\tloss:0.8243400454521179\n",
      "epoch:94\ttest_data_loss:0.012895413303375245\tAccurate59.910000%\n",
      "epoch:95\tbatch:0\tloss:0.730658769607544\n",
      "epoch:95\tbatch:1\tloss:0.7524699568748474\n",
      "epoch:95\tbatch:2\tloss:0.47555482387542725\n",
      "epoch:95\tbatch:3\tloss:0.616936445236206\n",
      "epoch:95\tbatch:4\tloss:0.8252308368682861\n",
      "epoch:95\ttest_data_loss:0.013015452116727829\tAccurate59.520000%\n",
      "epoch:96\tbatch:0\tloss:0.7283960580825806\n",
      "epoch:96\tbatch:1\tloss:0.7443860769271851\n",
      "epoch:96\tbatch:2\tloss:0.46249961853027344\n",
      "epoch:96\tbatch:3\tloss:0.5884655117988586\n",
      "epoch:96\tbatch:4\tloss:0.8256667256355286\n",
      "epoch:96\ttest_data_loss:0.01306050174832344\tAccurate59.630000%\n",
      "epoch:97\tbatch:0\tloss:0.7096920609474182\n",
      "epoch:97\tbatch:1\tloss:0.7447115182876587\n",
      "epoch:97\tbatch:2\tloss:0.4614408016204834\n",
      "epoch:97\tbatch:3\tloss:0.6058042645454407\n",
      "epoch:97\tbatch:4\tloss:0.8241249322891235\n",
      "epoch:97\ttest_data_loss:0.01324879680275917\tAccurate59.010000%\n",
      "epoch:98\tbatch:0\tloss:0.7114317417144775\n",
      "epoch:98\tbatch:1\tloss:0.7325578927993774\n",
      "epoch:98\tbatch:2\tloss:0.45755741000175476\n",
      "epoch:98\tbatch:3\tloss:0.5789157152175903\n",
      "epoch:98\tbatch:4\tloss:0.8268184661865234\n",
      "epoch:98\ttest_data_loss:0.013244137221574784\tAccurate59.220000%\n",
      "epoch:99\tbatch:0\tloss:0.7111270427703857\n",
      "epoch:99\tbatch:1\tloss:0.7397462725639343\n",
      "epoch:99\tbatch:2\tloss:0.4659014642238617\n",
      "epoch:99\tbatch:3\tloss:0.5717681646347046\n",
      "epoch:99\tbatch:4\tloss:0.8100776076316833\n",
      "epoch:99\ttest_data_loss:0.013112578052282333\tAccurate59.910000%\n"
     ]
    }
   ],
   "source": [
    "#由于Sequential里面只能是类,而view和reshape都是方法因此需要定义一个Flatten类\n",
    "#将它放在Sequential里头\n",
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Flatten,self).__init__()\n",
    "        \n",
    "    def forward(self,input):\n",
    "        return input.view(input.size(0),-1)\n",
    "class  lenet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(lenet5,self).__init__()\n",
    "        \n",
    "        self.module = nn.Sequential(\n",
    "            nn.Conv2d(3,6,kernel_size=5,stride=1,padding=0),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2,padding=0),\n",
    "            nn.Conv2d(6,16,kernel_size=5,stride=1,padding=0),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2,padding=0),\n",
    "            Flatten(),\n",
    "            nn.Linear(16*5*5,120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120,84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84,10)\n",
    "            )\n",
    "        #tem = torch.randn(2,3,32,32)\n",
    "       # out = self.module(tem)\n",
    "        #print(out.shape\n",
    "    #self.loss_fun = nn.CrossEntropyLoss() \n",
    "    def forward(self,x):\n",
    "        logits = self.module(x)\n",
    "        #loss = self.loss_fun(logits,y)\n",
    "        return logits\n",
    "epochs = 100\n",
    "device = torch.device('cuda:0')\n",
    "Lenet5 = lenet5().to(device)\n",
    "loss_fun = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.SGD(Lenet5.parameters(),lr = 1e-3)\n",
    "for epoch in range(epochs):\n",
    "    Lenet5.train()\n",
    "    for batch_idx,(data,label) in enumerate(train_data):\n",
    "        for i in range(100):\n",
    "            datas = data[i*100:(i+1)*100,:,:,:]\n",
    "            #print(data.shape)\n",
    "            datas = datas.to(device)\n",
    "            #print(data.shape)\n",
    "            logits = Lenet5(datas)\n",
    "            labels  =  label[i*100:(i+1)*100]\n",
    "            labels = labels.to(device)\n",
    "            loss  = loss_fun(logits,labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print('epoch:{}\\tbatch:{}\\tloss:{}'.format(epoch,batch_idx,loss.item()))\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    Lenet5.eval()\n",
    "    with  torch.no_grad():\n",
    "        for batch_idx,(data,label) in enumerate(test_data):\n",
    "            for i in range(100):\n",
    "                datas = data[i*100:(i+1)*100,:,:,:]\n",
    "                datas =  datas.to(device)\n",
    "                labels = label[i*100:(i+1)*100]\n",
    "                labels = labels.to(device)\n",
    "                logits = Lenet5(datas)\n",
    "                loss += loss_fun(logits,labels).item()\n",
    "                predict = logits.argmax(dim=1)\n",
    "                correct += predict.eq(labels).float().sum().item()\n",
    "        loss /=len(label)\n",
    "        print('epoch:{}\\ttest_data_loss:{}\\tAccurate{:2f}%'.format(epoch,loss,100.*correct/len(label))) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
